{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH0AO7C9eBEP"
   },
   "source": [
    "# 1-Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWswCrSweLbQ"
   },
   "source": [
    "Basado en: https://medium.com/analytics-vidhya/finetuning-bert-using-ktrain-for-disaster-tweets-classification-18f64a50910b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4koPLXdUeDio"
   },
   "source": [
    "## Objetivos\n",
    "Participar en la competencia de Kaggle 'Real or Not', donde se deben utilizar los datos de Tweets que nos brinda Kaggle en 2 archivos CSVs. Debemos clasificar los Tweets que hablan sobre desastres naturales contra los que NO hablan de estos (Y generalmente hablan de los mismos \"metafóricamente\"). \n",
    "\n",
    "Link set de datos y competencia: https://www.kaggle.com/c/nlp-getting-started\n",
    "\n",
    "De esta manera, como dijimos previamente, debemos identificar y clasificar si los tweets corresponden o no a tweets que hablan sobre catástrofes. Tenemos un dataset 'train' con una columna 'target' donde \"etiquetamos\" cuales son verdaderos (1) o falsos (0). Identificar esto es una tarea compleja debido a la ambigüedad en la estructura lingüística de los tweets y, por lo tanto, no siempre está claro si las palabras de una persona realmente están anunciando un desastre o no. Por ejemplo, si una persona tuitea:\n",
    "“On the plus side look at the sky last night, it was ablaze” (En español: \n",
    "\"En el lado positivo, miré el cielo anoche, estaba en llamas\"). \n",
    "La expresión 'ablaze' no significa que está en llamas realmente, sino que es una metáfora indicando que el cielo está anaranjado. Para nosotros es fácil entenderlo, pero para las máquinas no lo es. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ap1TzJZzhQm4"
   },
   "source": [
    "## Importamos Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "n3poTF1FhNXM",
    "outputId": "fe4b36af-042c-446a-d304-90ee6e2575cf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yt_gaYYHehZR"
   },
   "source": [
    "# 2-Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Etphmj0ek5w"
   },
   "source": [
    "## Cargamos los datos csv locales descargados de Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBZBNKqyeiCJ"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Dataset/train.csv')\n",
    "df_test = pd.read_csv('Dataset/test.csv')\n",
    "df_Sample_Subm = pd.read_csv('Dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Bnn7J05iqx9"
   },
   "source": [
    "## Exploración mínima de los datos (la exploración completa la hicimos en el TP1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtQQpVh1mhzy"
   },
   "source": [
    "Nuestras Columnas del dataset son:\n",
    " - id: Identificador único de cada tweet\n",
    " - keyword: Una palabra clave particular de cada tweet (puede ser NaN)\n",
    " - location - El lugar donde fue emitido el tweet (puede ser NaN)\n",
    " - text: texto del tweet\n",
    " - target: Si el tweet trata acerca de un desastre real, el valor es 1, sino 0  (solo en train.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "87jME07bi31u",
    "outputId": "a8fded78-bbec-4f34-fa3b-d5b4d6d6a5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5) (3263, 4) (3263, 2)\n"
     ]
    }
   ],
   "source": [
    "print (df_train.shape, df_test.shape, df_Sample_Subm.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "NQ7ibtUWhaXM",
    "outputId": "e678a7b2-a16e-4d33-c32a-d96d464bde95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "YmenbLOpjDzH",
    "outputId": "5341a70d-ce8d-4ed5-8048-ba6a20ecc157"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They'd probably still show more life than Arse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a nice hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck off!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
       "5  12     NaN      NaN                 We're shaking...It's an earthquake\n",
       "6  21     NaN      NaN  They'd probably still show more life than Arse...\n",
       "7  22     NaN      NaN                                  Hey! How are you?\n",
       "8  27     NaN      NaN                                   What a nice hat?\n",
       "9  29     NaN      NaN                                          Fuck off!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "uiunZcDujXeg",
    "outputId": "6044671b-73d7-405c-82ac-f22675198809",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0\n",
       "5  12       0\n",
       "6  21       0\n",
       "7  22       0\n",
       "8  27       0\n",
       "9  29       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Sample_Subm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train['keyword'].notnull() == False,'cleaned_text'] = df_train['text'] \n",
    "df_train.loc[df_train['keyword'].notnull() == True,'cleaned_text'] = df_train['keyword'] + ' ' + df_train['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test['keyword'].notnull() == False,'cleaned_text'] = df_test['text'] \n",
    "df_test.loc[df_test['keyword'].notnull() == True,'cleaned_text'] = df_test['keyword'] + ' ' + df_test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_line(text):\n",
    "    text = re.sub(r'\\t', ' ', text) # remove tabs\n",
    "    text = re.sub(r'\\n', ' ', text) # remove line jump\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url(text):\n",
    "# quite many tweets are truncated like \"Experts in France \n",
    "# begin examining airplane debris found on Reunion Island: French air \n",
    "# accident experts o... http://t.co/YVVPznZmXg #news\" , the explanation is above\n",
    "    text = re.sub(r' \\w{1,3}\\.{3,3} http\\S{0,}', ' ', text)\n",
    "    text = re.sub(r' \\w{1,3}Û_ http\\S{0,}', ' ', text)\n",
    "# some symbols and words one space before 'http' are eliminated, it is assumed the words have no a \n",
    "# semantical meaning and predictive power in the position. \n",
    "    text = re.sub(r\"mp3 http\\S{0,}\", r\" \", text)\n",
    "    text = re.sub(r\"rar http\\S{0,}\", r\" \", text)\n",
    "    pattern = re.compile(r'( pin\\:\\d+ | via )http\\S{0,}')\n",
    "    text = pattern.sub(r' ', text)\n",
    "# the pattern in tweet context have no a big meaning and the elimination of the words \n",
    "# unify the strings structure \n",
    "    pattern = re.compile(r'Full read by|Full read b|Full read|Full rea|Full re|Full r')\n",
    "    text = pattern.sub(r' ', text)\n",
    "    pattern = re.compile(r'Full story at|Full story a|Full story|Full stor|Full sto|Full st|Full s')\n",
    "    text = pattern.sub(r' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):    \n",
    "    text = new_line(text)\n",
    "# eliminate the pattern\n",
    "    text = re.sub(r'(&amp;|&gt;|&lt;)', \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra spaces\n",
    "    text = url(text)\n",
    "    \n",
    "# the pattern is 'translated as 'USER'\n",
    "# in https://www.kaggle.com/quentinsarrazin/tweets-preprocessing similar 'translation' is used\n",
    "# in https://arxiv.org/ftp/arxiv/papers/1807/1807.07752.pdf similar pattern \n",
    "# is 'translated as 'USER_NAME'\n",
    "    text = re.sub(r'@\\S{0,}', ' USER ', text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra spaces  \n",
    "# shrink multiple USER USER USER ... to USER\n",
    "    text = re.sub(r'\\b(USER)( \\1\\b)+', r'\\1', text)\n",
    "    \n",
    "# multiple  letters repeats like in 'Oooooohhh' are truncated to 2 letters, not possible to truncate \n",
    "# to 1 letter, because it may generated false meaning like  'good' to 'god'\n",
    "    text = re.sub(r'([a-zA-Z])\\1{1,}', r'\\1\\1', text)\n",
    "    \n",
    "#  URLs , if not yet eliminated by url function are eliminated \n",
    "    text = re.sub(r\"htt\\S{0,}\", \" \", text)\n",
    "    \n",
    "# remove all characters if not in the list [a-zA-Z\\d\\s]\n",
    "    text = re.sub(r\"[^a-zA-Z\\d\\s]\", \" \", text)\n",
    "    \n",
    "# the digit(s) pattern is 'translated' to 'NUMBER'\n",
    "# in https://www.kaggle.com/quentinsarrazin/tweets-preprocessing similar 'translation' is used\n",
    "    text = re.sub(r'^\\d\\S{0,}| \\d\\S{0,}| \\d\\S{0,}$', ' NUMBER ', text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra spaces \n",
    "# shrink multiple NUMBER NUMBER  ... to NUMBER\n",
    "    text = re.sub(r'\\b(NUMBER)( \\1\\b)+', r'\\1', text)\n",
    "    \n",
    "# remove digits if not eliminated above in 'NUMBER translation'\n",
    "    text = re.sub(r\"[0-9]\", \" \", text)\n",
    "    \n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string    \n",
    "# to reveal more equivalence classes the ' via USER' at the end of string is eliminated\n",
    "    text = re.sub(r' via\\s{1,}USER$', ' ', text)\n",
    "    \n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.cleaned_text = df_train.cleaned_text.apply(clean)\n",
    "df_test.cleaned_text = df_test.cleaned_text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the stage of text processing:\n",
      "...the size of longest text string in train set is  171\n",
      "...the size of longest text string in test set is  161\n"
     ]
    }
   ],
   "source": [
    "max_length_tr = df_train.cleaned_text.map(len).max()\n",
    "max_length_te = df_test.cleaned_text.map(len).max()\n",
    "max_length = max(max_length_tr, max_length_te)\n",
    "\n",
    "print(\"At the stage of text processing:\")\n",
    "print(f\"...the size of longest text string in train set is  {max_length_tr}\")\n",
    "print(f\"...the size of longest text string in test set is  {max_length_te}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After we cut tails of the longest tweets:\n",
      "...the size of longest text string in train set is  146\n",
      "...the size of longest text string in test set is  146\n"
     ]
    }
   ],
   "source": [
    "# the new max possible length will be (max_length - delta) , strings longer than new_max will be \n",
    "# decreased to new_max \n",
    "def cut(max_len, delta, x):\n",
    "    new_max = max_len - delta\n",
    "    length = len(x)\n",
    "    if length <= new_max:\n",
    "        return x \n",
    "    else:\n",
    "        return x[:(new_max-length)]\n",
    "    \n",
    "\n",
    "delta = 25 \n",
    "df_train.cleaned_text = df_train.cleaned_text.map(lambda x: cut(max_length, delta, x))\n",
    "df_test.cleaned_text = df_test.cleaned_text.map(lambda x: cut(max_length, delta, x))\n",
    "\n",
    "new_max_length_tr = df_train.cleaned_text.map(len).max()\n",
    "new_max_length_te = df_test.cleaned_text.map(len).max()\n",
    "\n",
    "print(\"After we cut tails of the longest tweets:\")\n",
    "print(f\"...the size of longest text string in train set is  {new_max_length_tr}\")\n",
    "print(f\"...the size of longest text string in test set is  {new_max_length_te}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRXc3E8YlPC-"
   },
   "source": [
    "# 3-Aproximación mediante BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k1kLvBG1lR0p"
   },
   "source": [
    "BERT (Bidirectional Encoder Representations from Transformers) es un modelo de deep learning desarrollado por Google de código abierto. Es utilizado por muchos investigadores e industrias para para resolver muchas tareas de NLP. \n",
    "\n",
    "Ktrain (https://github.com/amaiya/ktrain) es un contenedor (wrapper) ligero para la biblioteca de deeplearning TensorFlow Keras (https://www.tensorflow.org/guide/keras/sequential_model) para ayudar a construir, entrenar e implementar ANN's y otros modelos de ML. Diseñado para hacer que el aprendizaje profundo (deep learning) y la IA sean más accesibles y fáciles de aplicar.\n",
    "\n",
    "Ktrain proporciona soporte para la aplicación de muchas arquitecturas de aprendizaje profundo pre-entrenadas en el dominio de NLP; y BERT es una de ellas. Para resolver este problema, utilizaremos la implementación del BERT pre-entrenado proporcionado por ktrain y lo afinaremos/tunearemos para clasificar si los tweets del desastre son reales o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPuc7-ZTnH8l"
   },
   "source": [
    "SOLO estamos interesados en la columna TEXTO y TARGET. Las cuales usaremos para clasificar nuestros Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqtOYxNHnje7"
   },
   "source": [
    "## Importamos las librerias para leer el csv de entrenamiento (train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLEzScXLnSfO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "using Keras version: 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TK2ZDBisXh5"
   },
   "source": [
    "\n",
    "## Obtenemos la variable predictora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuestro train.csv está en el DF 'df_train'\n",
    "random_seed = 12342\n",
    "x_train, x_val, y_train, y_val = train_test_split(df_train['cleaned_text'], df_train['target'], shuffle=True, test_size = 0.2, random_state=random_seed, stratify=df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train_bert,  y_train_bert), (x_val_bert, y_val_bert), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
    "                                                                                         x_test = x_val, y_test=y_val,\n",
    "                                                                                          class_names= [\"0\", \"1\"],\n",
    "                                                                                          preprocess_mode='bert',\n",
    "                                                                                          lang = 'en',\n",
    "                                                                                          maxlen=65, \n",
    "                                                                                          max_features=35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 65\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('bert', train_data=(x_train_bert, y_train_bert), preproc=preproc)\n",
    "learner = ktrain.get_learner(model, train_data=(x_train_bert, y_train_bert), val_data=(x_val_bert, y_val_bert), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learner.lr_find()    #SImulamos un entrenamiento para encontrar el mejor LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para observar el plot del LR:\n",
    "#learner.lr_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early_stopping automatically enabled at patience=5\n",
      "reduce_on_plateau automatically enabled at patience=2\n",
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 1e-05...\n",
      "Train on 6090 samples, validate on 1523 samples\n",
      "Epoch 1/1024\n",
      "6090/6090 [==============================] - 163s 27ms/sample - loss: 0.4894 - acc: 0.7798 - val_loss: 0.3820 - val_acc: 0.8424\n",
      "Epoch 2/1024\n",
      "6090/6090 [==============================] - 165s 27ms/sample - loss: 0.3810 - acc: 0.8455 - val_loss: 0.3771 - val_acc: 0.8450\n",
      "Epoch 3/1024\n",
      "6090/6090 [==============================] - 165s 27ms/sample - loss: 0.3319 - acc: 0.8716 - val_loss: 0.3874 - val_acc: 0.8418\n",
      "Epoch 4/1024\n",
      "6090/6090 [==============================] - ETA: 0s - loss: 0.2872 - acc: 0.8924\n",
      "Epoch 00004: Reducing Max LR on Plateau: new max lr will be 5e-06 (if not early_stopping).\n",
      "6090/6090 [==============================] - 165s 27ms/sample - loss: 0.2872 - acc: 0.8924 - val_loss: 0.3939 - val_acc: 0.8345\n",
      "Epoch 5/1024\n",
      "6090/6090 [==============================] - 165s 27ms/sample - loss: 0.2381 - acc: 0.9151 - val_loss: 0.4151 - val_acc: 0.8372\n",
      "Epoch 6/1024\n",
      "6090/6090 [==============================] - ETA: 0s - loss: 0.2053 - acc: 0.9274\n",
      "Epoch 00006: Reducing Max LR on Plateau: new max lr will be 2.5e-06 (if not early_stopping).\n",
      "6090/6090 [==============================] - 165s 27ms/sample - loss: 0.2053 - acc: 0.9274 - val_loss: 0.4502 - val_acc: 0.8313\n",
      "Epoch 7/1024\n",
      "6090/6090 [==============================] - ETA: 0s - loss: 0.1731 - acc: 0.9420Restoring model weights from the end of the best epoch.\n",
      "6090/6090 [==============================] - 166s 27ms/sample - loss: 0.1731 - acc: 0.9420 - val_loss: 0.4771 - val_acc: 0.8253\n",
      "Epoch 00007: early stopping\n",
      "Weights from best epoch have been loaded into model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ac0367f10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.autofit(1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Disaster       0.86      0.88      0.87       869\n",
      "    Disaster       0.83      0.80      0.82       654\n",
      "\n",
      "    accuracy                           0.85      1523\n",
      "   macro avg       0.84      0.84      0.84      1523\n",
      "weighted avg       0.84      0.85      0.84      1523\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[762, 107],\n",
       "       [129, 525]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.validate(val_data=(x_val_bert, y_val_bert), class_names=['No Disaster', 'Disaster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "learner.model.save_weights(\"model-bert-more-cleaning.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYcANcCEshUL"
   },
   "source": [
    "## Predecimos en el CSV de TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVdCi9HNsj4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test[\"target\"] = predictor.predict(df_test[\"cleaned_text\"].tolist())\n",
    "df_test = df_test[[\"id\", \"target\"]]\n",
    "df_test.to_csv(\"submission_bert_more_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmyKVrjGudFh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP2-BERT_COLAB.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
