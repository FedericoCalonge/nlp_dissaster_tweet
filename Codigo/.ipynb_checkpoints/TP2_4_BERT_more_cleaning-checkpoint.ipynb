{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DH0AO7C9eBEP"
   },
   "source": [
    "# 1-Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vWswCrSweLbQ"
   },
   "source": [
    "Basado en: https://medium.com/analytics-vidhya/finetuning-bert-using-ktrain-for-disaster-tweets-classification-18f64a50910b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4koPLXdUeDio"
   },
   "source": [
    "## Objetivos\n",
    "Participar en la competencia de Kaggle 'Real or Not', donde se deben utilizar los datos de Tweets que nos brinda Kaggle en 2 archivos CSVs. Debemos clasificar los Tweets que hablan sobre desastres naturales contra los que NO hablan de estos (Y generalmente hablan de los mismos \"metafóricamente\"). \n",
    "\n",
    "Link set de datos y competencia: https://www.kaggle.com/c/nlp-getting-started\n",
    "\n",
    "De esta manera, como dijimos previamente, debemos identificar y clasificar si los tweets corresponden o no a tweets que hablan sobre catástrofes. Tenemos un dataset 'train' con una columna 'target' donde \"etiquetamos\" cuales son verdaderos (1) o falsos (0). Identificar esto es una tarea compleja debido a la ambigüedad en la estructura lingüística de los tweets y, por lo tanto, no siempre está claro si las palabras de una persona realmente están anunciando un desastre o no. Por ejemplo, si una persona tuitea:\n",
    "“On the plus side look at the sky last night, it was ablaze” (En español: \n",
    "\"En el lado positivo, miré el cielo anoche, estaba en llamas\"). \n",
    "La expresión 'ablaze' no significa que está en llamas realmente, sino que es una metáfora indicando que el cielo está anaranjado. Para nosotros es fácil entenderlo, pero para las máquinas no lo es. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ap1TzJZzhQm4"
   },
   "source": [
    "## Importamos Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "n3poTF1FhNXM",
    "outputId": "fe4b36af-042c-446a-d304-90ee6e2575cf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#from wordcloud import WordCloud, STOPWORDS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yt_gaYYHehZR"
   },
   "source": [
    "# 2-Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Etphmj0ek5w"
   },
   "source": [
    "## Cargamos los datos csv locales descargados de Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBZBNKqyeiCJ"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Dataset/train.csv')\n",
    "df_test = pd.read_csv('Dataset/test.csv')\n",
    "df_Sample_Subm = pd.read_csv('Dataset/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Bnn7J05iqx9"
   },
   "source": [
    "## Exploración mínima de los datos (la exploración completa la hicimos en el TP1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VtQQpVh1mhzy"
   },
   "source": [
    "Nuestras Columnas del dataset son:\n",
    " - id: Identificador único de cada tweet\n",
    " - keyword: Una palabra clave particular de cada tweet (puede ser NaN)\n",
    " - location - El lugar donde fue emitido el tweet (puede ser NaN)\n",
    " - text: texto del tweet\n",
    " - target: Si el tweet trata acerca de un desastre real, el valor es 1, sino 0  (solo en train.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "87jME07bi31u",
    "outputId": "a8fded78-bbec-4f34-fa3b-d5b4d6d6a5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5) (3263, 4) (3263, 2)\n"
     ]
    }
   ],
   "source": [
    "print (df_train.shape, df_test.shape, df_Sample_Subm.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "NQ7ibtUWhaXM",
    "outputId": "e678a7b2-a16e-4d33-c32a-d96d464bde95"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#RockyFire Update =&gt; California Hwy. 20 closed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster Heavy rain causes flash flood...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm on top of the hill and I can see a fire in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's an emergency evacuation happening now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "5   8     NaN      NaN  #RockyFire Update => California Hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster Heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  I'm on top of the hill and I can see a fire in...   \n",
       "8  14     NaN      NaN  There's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  I'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "YmenbLOpjDzH",
    "outputId": "5341a70d-ce8d-4ed5-8048-ba6a20ecc157"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They'd probably still show more life than Arse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a nice hat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck off!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n",
       "5  12     NaN      NaN                 We're shaking...It's an earthquake\n",
       "6  21     NaN      NaN  They'd probably still show more life than Arse...\n",
       "7  22     NaN      NaN                                  Hey! How are you?\n",
       "8  27     NaN      NaN                                   What a nice hat?\n",
       "9  29     NaN      NaN                                          Fuck off!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "uiunZcDujXeg",
    "outputId": "6044671b-73d7-405c-82ac-f22675198809",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       0\n",
       "1   2       0\n",
       "2   3       0\n",
       "3   9       0\n",
       "4  11       0\n",
       "5  12       0\n",
       "6  21       0\n",
       "7  22       0\n",
       "8  27       0\n",
       "9  29       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Sample_Subm.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_line(text):\n",
    "    text = re.sub(r'\\t', ' ', text) # remove tabs\n",
    "    text = re.sub(r'\\n', ' ', text) # remove line jump\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url(text):\n",
    "# quite many tweets are truncated like \"Experts in France \n",
    "# begin examining airplane debris found on Reunion Island: French air \n",
    "# accident experts o... http://t.co/YVVPznZmXg #news\" , the explanation is above\n",
    "    text = re.sub(r' \\w{1,3}\\.{3,3} http\\S{0,}', ' ', text)\n",
    "    text = re.sub(r' \\w{1,3}Û_ http\\S{0,}', ' ', text)\n",
    "# some symbols and words one space before 'http' are eliminated, it is assumed the words have no a \n",
    "# semantical meaning and predictive power in the position. \n",
    "    text = re.sub(r\"mp3 http\\S{0,}\", r\" \", text)\n",
    "    text = re.sub(r\"rar http\\S{0,}\", r\" \", text)\n",
    "    pattern = re.compile(r'( pin\\:\\d+ | via )http\\S{0,}')\n",
    "    text = pattern.sub(r' ', text)\n",
    "# the pattern in tweet context have no a big meaning and the elimination of the words \n",
    "# unify the strings structure \n",
    "    pattern = re.compile(r'Full read by|Full read b|Full read|Full rea|Full re|Full r')\n",
    "    text = pattern.sub(r' ', text)\n",
    "    pattern = re.compile(r'Full story at|Full story a|Full story|Full stor|Full sto|Full st|Full s')\n",
    "    text = pattern.sub(r' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):    \n",
    "    text = new_line(text)\n",
    "# eliminate the pattern\n",
    "    text = re.sub(r'(&amp;|&gt;|&lt;)', \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra spaces\n",
    "    text = url(text)\n",
    "    \n",
    "# the pattern is 'translated as 'USER'\n",
    "# in https://www.kaggle.com/quentinsarrazin/tweets-preprocessing similar 'translation' is used\n",
    "# in https://arxiv.org/ftp/arxiv/papers/1807/1807.07752.pdf similar pattern \n",
    "# is 'translated as 'USER_NAME'\n",
    "    text = re.sub(r'@\\S{0,}', ' USER ', text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra spaces  \n",
    "# shrink multiple USER USER USER ... to USER\n",
    "    text = re.sub(r'\\b(USER)( \\1\\b)+', r'\\1', text)\n",
    "    \n",
    "# multiple  letters repeats like in 'Oooooohhh' are truncated to 2 letters, not possible to truncate \n",
    "# to 1 letter, because it may generated false meaning like  'good' to 'god'\n",
    "    text = re.sub(r'([a-zA-Z])\\1{1,}', r'\\1\\1', text)\n",
    "    \n",
    "#  URLs , if not yet eliminated by url function are eliminated \n",
    "    text = re.sub(r\"htt\\S{0,}\", \" \", text)\n",
    "    \n",
    "# remove all characters if not in the list [a-zA-Z\\d\\s]\n",
    "    text = re.sub(r\"[^a-zA-Z\\d\\s]\", \" \", text)\n",
    "    \n",
    "# the digit(s) pattern is 'translated' to 'NUMBER'\n",
    "# in https://www.kaggle.com/quentinsarrazin/tweets-preprocessing similar 'translation' is used\n",
    "    text = re.sub(r'^\\d\\S{0,}| \\d\\S{0,}| \\d\\S{0,}$', ' NUMBER ', text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra spaces \n",
    "# shrink multiple NUMBER NUMBER  ... to NUMBER\n",
    "    text = re.sub(r'\\b(NUMBER)( \\1\\b)+', r'\\1', text)\n",
    "    \n",
    "# remove digits if not eliminated above in 'NUMBER translation'\n",
    "    text = re.sub(r\"[0-9]\", \" \", text)\n",
    "    \n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string    \n",
    "# to reveal more equivalence classes the ' via USER' at the end of string is eliminated\n",
    "    text = re.sub(r' via\\s{1,}USER$', ' ', text)\n",
    "    \n",
    "    text = re.sub(r\"\\s+\", \" \", text) # remove extra spaces\n",
    "    text = text.strip() # remove spaces at the beginning and at the end of string\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRXc3E8YlPC-"
   },
   "source": [
    "# 3-Aproximación mediante BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k1kLvBG1lR0p"
   },
   "source": [
    "BERT (Bidirectional Encoder Representations from Transformers) es un modelo de deep learning desarrollado por Google de código abierto. Es utilizado por muchos investigadores e industrias para para resolver muchas tareas de NLP. \n",
    "\n",
    "Ktrain (https://github.com/amaiya/ktrain) es un contenedor (wrapper) ligero para la biblioteca de deeplearning TensorFlow Keras (https://www.tensorflow.org/guide/keras/sequential_model) para ayudar a construir, entrenar e implementar ANN's y otros modelos de ML. Diseñado para hacer que el aprendizaje profundo (deep learning) y la IA sean más accesibles y fáciles de aplicar.\n",
    "\n",
    "Ktrain proporciona soporte para la aplicación de muchas arquitecturas de aprendizaje profundo pre-entrenadas en el dominio de NLP; y BERT es una de ellas. Para resolver este problema, utilizaremos la implementación del BERT pre-entrenado proporcionado por ktrain y lo afinaremos/tunearemos para clasificar si los tweets del desastre son reales o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPuc7-ZTnH8l"
   },
   "source": [
    "SOLO estamos interesados en la columna TEXTO y TARGET. Las cuales usaremos para clasificar nuestros Tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqtOYxNHnje7"
   },
   "source": [
    "## Importamos las librerias para leer el csv de entrenamiento (train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wLEzScXLnSfO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "using Keras version: 2.3.0-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5TK2ZDBisXh5"
   },
   "source": [
    "\n",
    "## Obtenemos la variable predictora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuestro train.csv está en el DF 'df_train'\n",
    "random_seed = 12342\n",
    "x_train, x_val, y_train, y_val = train_test_split(df_train['text'], df_train['target'], shuffle=True, test_size = 0.2, random_state=random_seed, stratify=df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train_bert,  y_train_bert), (x_val_bert, y_val_bert), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
    "                                                                                         x_test = x_val, y_test=y_val,\n",
    "                                                                                          class_names= [\"0\", \"1\"],\n",
    "                                                                                          preprocess_mode='bert',\n",
    "                                                                                          lang = 'en',\n",
    "                                                                                          maxlen=65, \n",
    "                                                                                          max_features=35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 65\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('bert', train_data=(x_train_bert, y_train_bert), preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model-bert-best-score.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"Dataset/test.csv\")\n",
    "test_df[\"target\"] = predictor.predict(test_df[\"text\"].tolist())\n",
    "test_df = test_df[[\"id\", \"target\"]]\n",
    "test_df.to_csv(\"submission_bert_load_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETTaFA3htp-k"
   },
   "source": [
    "La variable predictora es obtenida pasandole el modelo y el objeto 'preproc' al mètodo 'get_predictor'. Este 'predictor' puede ser usado para realizar predicciones en nuestra data de TEST directamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgnHeBHBscnD"
   },
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72H4yYlOse7S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (trainable=True) : <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fc437160390>\n",
      "1 (trainable=True) : <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fc49403e090>\n",
      "2 (trainable=True) : <keras_bert.layers.embedding.TokenEmbedding object at 0x7fc494153d10>\n",
      "3 (trainable=True) : <tensorflow.python.keras.layers.embeddings.Embedding object at 0x7fc437160710>\n",
      "4 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc4368384d0>\n",
      "5 (trainable=True) : <keras_pos_embd.pos_embd.PositionEmbedding object at 0x7fc436838a50>\n",
      "6 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc436879cd0>\n",
      "7 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc4366d1fd0>\n",
      "8 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc43676c9d0>\n",
      "9 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc4370d0890>\n",
      "10 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc438ec34d0>\n",
      "11 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc4366c77d0>\n",
      "12 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc4366ad350>\n",
      "13 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc4367d5b90>\n",
      "14 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc43684bd50>\n",
      "15 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc437109790>\n",
      "16 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc4365be090>\n",
      "17 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc43658db90>\n",
      "18 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc4367d5510>\n",
      "19 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc43658de90>\n",
      "20 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc4366fb9d0>\n",
      "21 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc43658d710>\n",
      "22 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc43671c250>\n",
      "23 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc43671f810>\n",
      "24 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc4366abb10>\n",
      "25 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc43662df90>\n",
      "26 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc4367b9950>\n",
      "27 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc43658d350>\n",
      "28 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc436771290>\n",
      "29 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc4364a08d0>\n",
      "30 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc436538490>\n",
      "31 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc4366b0b10>\n",
      "32 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc436763590>\n",
      "33 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc4363ff710>\n",
      "34 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc4366c7910>\n",
      "35 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc4365f9990>\n",
      "36 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc4363a8e90>\n",
      "37 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc4367b9210>\n",
      "38 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc436336f90>\n",
      "39 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc43633cf50>\n",
      "40 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc436302a50>\n",
      "41 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc436489710>\n",
      "42 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc4366d2ad0>\n",
      "43 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc43675a350>\n",
      "44 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc4362b2710>\n",
      "45 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc436266910>\n",
      "46 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc4364ce050>\n",
      "47 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc436256750>\n",
      "48 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc436661350>\n",
      "49 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc4361b8950>\n",
      "50 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc436221ed0>\n",
      "51 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc4361c9f10>\n",
      "52 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc4361d3290>\n",
      "53 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc436659d50>\n",
      "54 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc436489890>\n",
      "55 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc43658de50>\n",
      "56 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc4365fe8d0>\n",
      "57 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc4360afb90>\n",
      "58 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc43611eb90>\n",
      "59 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc436121f50>\n",
      "60 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc4360c05d0>\n",
      "61 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc436067f50>\n",
      "62 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc43606d2d0>\n",
      "63 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc4366ffd50>\n",
      "64 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc436763f90>\n",
      "65 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435fcffd0>\n",
      "66 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435fd3f90>\n",
      "67 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc435fb7550>\n",
      "68 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc43677e550>\n",
      "69 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435f14b50>\n",
      "70 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc43675a690>\n",
      "71 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc4366616d0>\n",
      "72 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc435f24f50>\n",
      "73 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435ee9690>\n",
      "74 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435e70b10>\n",
      "75 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc435ed4450>\n",
      "76 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc4366eaa10>\n",
      "77 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435db2d50>\n",
      "78 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435db6b50>\n",
      "79 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc435e24750>\n",
      "80 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc436602510>\n",
      "81 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435d84c10>\n",
      "82 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435d71f50>\n",
      "83 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc4407927d0>\n",
      "84 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc435cbcd90>\n",
      "85 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435cc0390>\n",
      "86 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435cc6250>\n",
      "87 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc43671ca90>\n",
      "88 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc435c8bd10>\n",
      "89 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435cac610>\n",
      "90 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435c91890>\n",
      "91 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc435c5b750>\n",
      "92 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc435c9aa50>\n",
      "93 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435b6e610>\n",
      "94 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435be7950>\n",
      "95 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc435b75510>\n",
      "96 (trainable=True) : <keras_multi_head.multi_head_attention.MultiHeadAttention object at 0x7fc435ba9990>\n",
      "97 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc435b3dbd0>\n",
      "98 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435b4bfd0>\n",
      "99 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc435b32850>\n",
      "100 (trainable=True) : <keras_position_wise_feed_forward.feed_forward.FeedForward object at 0x7fc436771710>\n",
      "101 (trainable=True) : <tensorflow.python.keras.layers.core.Dropout object at 0x7fc4366ff710>\n",
      "102 (trainable=True) : <tensorflow.python.keras.layers.merge.Add object at 0x7fc435a8bfd0>\n",
      "103 (trainable=True) : <keras_layer_normalization.layer_normalization.LayerNormalization object at 0x7fc435a90ed0>\n",
      "104 (trainable=True) : <keras_bert.layers.extract.Extract object at 0x7fc4359e1890>\n",
      "105 (trainable=True) : <tensorflow.python.keras.layers.core.Dense object at 0x7fc4359e1990>\n",
      "106 (trainable=True) : <tensorflow.python.keras.layers.core.Dense object at 0x7fc435374ad0>\n"
     ]
    }
   ],
   "source": [
    "learner.print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "learner.model.save_weights(\"model-bert.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xYcANcCEshUL"
   },
   "source": [
    "## Predecimos en el CSV de TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GVdCi9HNsj4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"Dataset/test.csv\")\n",
    "test_df[\"target\"] = predictor.predict(test_df[\"text\"].tolist())\n",
    "test_df = test_df[[\"id\", \"target\"]]\n",
    "test_df.to_csv(\"submission_bert_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Disaster Probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wreckage</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debris</th>\n",
       "      <td>37</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derailment</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outbreak</th>\n",
       "      <td>40</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil%20spill</th>\n",
       "      <td>38</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typhoon</th>\n",
       "      <td>38</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide%20bombing</th>\n",
       "      <td>33</td>\n",
       "      <td>0.969697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide%20bomber</th>\n",
       "      <td>31</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bombing</th>\n",
       "      <td>29</td>\n",
       "      <td>0.931034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide%20bomb</th>\n",
       "      <td>35</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rescuers</th>\n",
       "      <td>35</td>\n",
       "      <td>0.914286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuclear%20disaster</th>\n",
       "      <td>34</td>\n",
       "      <td>0.911765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evacuated</th>\n",
       "      <td>36</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>razed</th>\n",
       "      <td>35</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wildfire</th>\n",
       "      <td>33</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wild%20fires</th>\n",
       "      <td>31</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airplane%20accident</th>\n",
       "      <td>35</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings%20on%20fire</th>\n",
       "      <td>33</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass%20murder</th>\n",
       "      <td>33</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest%20fires</th>\n",
       "      <td>32</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Count  Disaster Probability\n",
       "keyword                                           \n",
       "wreckage                  39              1.000000\n",
       "debris                    37              1.000000\n",
       "derailment                39              1.000000\n",
       "outbreak                  40              0.975000\n",
       "oil%20spill               38              0.973684\n",
       "typhoon                   38              0.973684\n",
       "suicide%20bombing         33              0.969697\n",
       "suicide%20bomber          31              0.967742\n",
       "bombing                   29              0.931034\n",
       "suicide%20bomb            35              0.914286\n",
       "rescuers                  35              0.914286\n",
       "nuclear%20disaster        34              0.911765\n",
       "evacuated                 36              0.888889\n",
       "razed                     35              0.885714\n",
       "wildfire                  33              0.878788\n",
       "wild%20fires              31              0.870968\n",
       "airplane%20accident       35              0.857143\n",
       "buildings%20on%20fire     33              0.848485\n",
       "mass%20murder             33              0.848485\n",
       "forest%20fires            32              0.843750"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"Dataset/train.csv\")\n",
    "train_df_copy = df_train\n",
    "train_df_copy = train_df_copy.fillna('None')\n",
    "ag = train_df_copy.groupby('keyword').agg({'text':np.size, 'target':np.mean}).rename(columns={'text':'Count', 'target':'Disaster Probability'})\n",
    "\n",
    "ag.sort_values('Disaster Probability', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bombing',\n",
       " 'debris',\n",
       " 'derailment',\n",
       " 'nuclear%20disaster',\n",
       " 'oil%20spill',\n",
       " 'outbreak',\n",
       " 'rescuers',\n",
       " 'suicide%20bomb',\n",
       " 'suicide%20bomber',\n",
       " 'suicide%20bombing',\n",
       " 'typhoon',\n",
       " 'wreckage']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 2\n",
    "prob_disaster = 0.9\n",
    "keyword_list_disaster = list(ag[(ag['Count']>count) & (ag['Disaster Probability']>=prob_disaster)].index)\n",
    "#we print the list of keywords which will be used for prediction correction \n",
    "keyword_list_disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'keyword'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ac8ddd828cfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mids_disaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyword_list_disaster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_disaster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bert/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'keyword'"
     ]
    }
   ],
   "source": [
    "ids_disaster = test_df['id'][test_df.keyword.isin(keyword_list_disaster)].values\n",
    "test_df['target'][test_df['id'].isin(ids_disaster)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[[\"id\", \"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTOse3O2sn91"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "84MBdhxgsqmj"
   },
   "outputs": [],
   "source": [
    "#test_df.to_csv(\"submission_bert_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FKF0paWft2kY"
   },
   "source": [
    "## Subimos las predicciones de TEST a Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wXLe_NRtuBBy"
   },
   "source": [
    "Como último paso subimos nuestras predicciones a Kaggle y chequeamos el SCORE obtenido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2ePjC3VmuQM9"
   },
   "source": [
    "VER.... Logramos una precisión del ......83.4% on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NsuqinTvua4A"
   },
   "source": [
    "# 3- Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5aHtbwJuud3a"
   },
   "source": [
    "Utilizamos las features de Ktrain para implementar de una manera sencilla el complejo modelo de BERT. AL final fuimos capaces de lograr una precisioǹ en TEST de .........\n",
    "\n",
    "Uno de los mayores problema con BERT es que toma mucho tiempo entrenando. Para mejorar esto, podemos aplicar una versiòn màs ligera de BERT como distilBERT. Tambien, para reducir el tiempo de entrenamiento, los pesos de todas las capas pueden ser congeladas (frozen) a excepciòn de la capa final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZmyKVrjGudFh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TP2-BERT_COLAB.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
